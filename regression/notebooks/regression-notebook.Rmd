---
title: Regression problem
subtitle: The release year prediction of the songs from the timbre features.
author: "Mateusz Bary≈Ça & Agata Wytrykowska"
bibliography: bibliography.bib
link-citations: yes
output:
  html_document:
    toc: yes
    df_print: paged
  pdf_document:
    toc: yes
    df_print: kable
    fig_width: 7
    fig_caption: yes
    html_document:
      number_sections: no
      theme: cerulean
      highligt: pygments
---

## Introduction*

Audio features play a significant role in the prediction of the song release year. The Million Song Dataset is a free collection of million music tracks consists. Based on this dataset a subset has been created that returned mostly the songs between 1922 to 2011, with the greatest number of observations in 2000s \cite{Bertin-Mahieux2011}. We downloaded it from the Machine Learning Repository \cite{Dua:2019}.
```{r}
pacman::p_load(data.table, tidyverse, knitr)
```

## Data Inspection
There are 515345 observations in the dataset. 90 attributes describe each and single observation. All of the attributes are real number and correspond to the timbre either average or covariance. The Echo Nest API is used in order to extract the features from the timbre which must be an additional service.
## Data Preprocessing

### Reading data
```{r}
raw_data <- read.csv('regression\\data\\raw\\YearPredictionMSD.txt',
                     header = FALSE)
```
```{r}
raw_data %>% head() %>% kable()
```


The first column in the dataset correspond to the year that will be predicted from the features. We rename it for the sake of the modelling purposes.
```{r}
raw_data <- raw_data %>%
        rename(year = V1)
raw_data %>% head() %>% kable()
```
In the next step we split the dataset into the attributes and the target variable. Thanks to that we will not mix the attributes in the feature engineering process.
```{r}
target_data <- raw_data %>% select(year)
target_data %>% head()
```
The result might suggest that the dataset is somehow not completely random. It is confirmed with the fact that the following train / test split should be respected. First 463 715 examples should be used for the training purposes while the remaing 51 630 are the observations on which the regression model will be tested.


```{r}
train_data <- raw_data %>% slice_head(n = 463715)
test_data <- raw_data %>% slice_tail(n = 51630)
```
The dataset authors add that thanks to that split 'producer effect' will be avoided. The justification for that is t
```{r}
covariates_data <- raw_data %>% select(-year)
covariates_data %>% kable() %>% head()
```
Next, we confirm that the remaining attributes correspond to the timbre covariates.
```{r}
timbre_average_data <- covariates_data %>%
        select(V2:V13)
timbre_average_data %>% head()
```
We needed to investigate what the timbre in the sound analysis actually means. It is described as everything that can be differentiated between two different tracks by the listener having kept the same pitch, spatial location and loudness and refers to the perceptual quality of a sound and color. "Brightness", "clarity", "harshness", "fullness" and "noisiness" are frequently used adjectives that are associated with the timbre word \cite{Allen2018}.
```{r}
timbre_covariance_data <- covariates_data %>%
        select(V14:V91)
timbre_covariance_data %>% head()
```
Two separate summaries are done for timbre average and covariance data.
```{r}
summary(timbre_average_data)
```


### handling missing

```{r}
raw_data %>%
        summarise(across(everything(), ~sum(is.na(.))))
```
There are no missing values across columns and in the whole dataset. This is an important insight that will allow for an easier later phases of the project e.g exploratory data analysis and modelling.

# Spotting duplicates
```{r}
(raw_data %>% dim())[1] - n_distinct(raw_data)
```
Since there are 214 duplicates in the data we see that there is need to decide what is the appropriate way of handling them.

## Exploratory Data Analysis

Having described the dataset we can follow the analysis and in the next points visualized dataset including both target and features on which the model will be trained.


### Two-dimensional plots

```{r}
ggplot(data = raw_data, aes(x = year)) +
        geom_bar(stat = 'count', aes(y = ..prop..))
```

## Model

## Diagnostics
<!-- Residuals Error Checking -->

## Forecast

## Analysis

## Conclusion

## References
<!-- This is required to attach the bibliography -->